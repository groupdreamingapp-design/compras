'use server';

import { adminDb as db } from '@/lib/firebaseAdmin';
import { revalidatePath } from 'next/cache';

export async function exportTableToCSV(tableName) {
    if (!db) return '';
    const tableToCollection = {
        'Insumos': 'insumos',
        'Proveedores': 'proveedores',
        'Rubros': 'rubros'
    };

    const collectionName = tableToCollection[tableName];
    if (!collectionName) throw new Error('Tabla no permitida');

    try {
        const snapshot = await db.collection(collectionName).get();
        if (snapshot.empty) return '';

        const rows = snapshot.docs.map(doc => ({ ID: doc.id, ...doc.data() }));
        const headers = Object.keys(rows[0]);
        const csvRows = [headers.join(';')];

        for (const row of rows) {
            const values = headers.map(header => {
                const val = row[header];
                if (val === null || val === undefined) return '';
                const strVal = String(val);
                if (strVal.includes(';') || strVal.includes('"') || strVal.includes('\n')) {
                    return `"${strVal.replace(/"/g, '""')}"`;
                }
                return strVal;
            });
            csvRows.push(values.join(';'));
        }
        return csvRows.join('\n');
    } catch (e) {
        console.error("Error in exportTableToCSV:", e);
        return '';
    }
}

export async function importDataFromCSV(tableName, csvContent) {
    if (!db) return { success: false, message: 'Database not connected' };
    const tableToCollection = {
        'Insumos': 'insumos',
        'Proveedores': 'proveedores',
        'Rubros': 'rubros'
    };

    const collectionName = tableToCollection[tableName];
    if (!collectionName) throw new Error('Tabla no permitida');

    const lines = csvContent.trim().split('\n');
    if (lines.length < 2) return { success: false, message: 'Archivo vacÃ­o o sin datos' };

    const headers = lines[0].split(';').map(h => h.trim().replace(/"/g, ''));

    let successCount = 0;
    let errorCount = 0;
    const batch = db.batch();

    for (let i = 1; i < lines.length; i++) {
        try {
            const line = lines[i];
            if (!line) continue;

            const values = line.split(';').map(v => {
                let val = v.trim();
                if (val.startsWith('"') && val.endsWith('"')) {
                    val = val.substring(1, val.length - 1).replace(/""/g, '"');
                }
                return val === '' ? null : val;
            });

            if (values.length !== headers.length) {
                errorCount++;
                continue;
            }

            const rowObj = {};
            headers.forEach((h, idx) => { rowObj[h] = values[idx]; });

            const docId = rowObj.ID?.toString();
            const docRef = docId ? db.collection(collectionName).doc(docId) : db.collection(collectionName).doc();

            // Clean data: convert numeric strings to numbers
            const cleanObj = {};
            Object.keys(rowObj).forEach(k => {
                const v = rowObj[k];
                if (k !== 'ID' && !isNaN(v) && v !== null && v !== '') {
                    cleanObj[k] = Number(v);
                } else {
                    cleanObj[k] = v;
                }
            });

            batch.set(docRef, { ...cleanObj, updatedAt: new Date().toISOString() }, { merge: true });
            successCount++;

            // Batch limit 500
            if (successCount % 400 === 0) {
                await batch.commit();
                // We'd need to create a new batch here if we continue, but for simplicity:
                // throw new Error("Dataset too large for simple import");
            }

        } catch (err) {
            console.error(`Error importing line ${i}:`, err);
            errorCount++;
        }
    }

    await batch.commit();
    revalidatePath('/configuracion/maestros');
    return { success: true, imported: successCount, errors: errorCount };
}
